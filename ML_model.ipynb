{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23790529-4392-4d88-8da8-402c65757513",
   "metadata": {},
   "source": [
    "# NMF machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03699e-14a8-47a9-b8f8-a3af04aeee31",
   "metadata": {},
   "source": [
    "### Import necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c00d41b-b40d-4e0f-b829-32b3329476ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "import keras\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee8e677-6d8a-4f17-aadd-f781a1f3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing numpy array to replicate our csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72617d4-1f9b-4056-9041-bf4a21568e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([\n",
    "    [0, 1, 0, 1, 2, 2, 0, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 1, 1, 3, 4, 1, 2] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [2, 3, 1, 1, 2, 2, 2, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [1, 1, 1, 0, 1, 1, 4, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 2, 3, 4, 1, 1, 2, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 0, 0, 0, 1, 0, 3, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 4, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 3, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 1, 1, 3, 4, 3, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [2, 3, 1, 1, 2, 2, 4, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [1, 1, 1, 0, 1, 1, 3, 2] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 2, 3, 4, 1, 1, 2, 3] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 3, 0] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 0, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 1, 1, 3, 4, 2, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [2, 3, 1, 1, 2, 2, 1, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [1, 1, 1, 0, 1, 1, 3, 2] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 2, 3, 4, 1, 1, 4, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 0, 0, 0, 1, 0, 3, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 0, 2] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 1, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 1, 1, 3, 4, 0, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [2, 3, 1, 1, 2, 2, 3, 0] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [1, 1, 1, 0, 1, 1, 1, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 2, 3, 4, 1, 1, 3, 4] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 0, 0, 0, 1, 0, 4, 1] + [round(np.random.rand(),3) for _ in range(5)],\n",
    "    [0, 1, 0, 1, 2, 2, 4, 3] + [round(np.random.rand(),3) for _ in range(5)]\n",
    "])\n",
    "\n",
    "for row in m:\n",
    "    row[:8] = np.random.randint(0, 2, size=8)\n",
    "\n",
    "# I've initialized the first half of the columns as 1's and 0's to mimic how the csv file will have 1's \n",
    "# for when the book can be found in that genre and 0's for when that book is not found in that genre\n",
    "# the second half of the columns I've given random floats to mimic the percentages that we'll gather from \n",
    "# the open library reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b688a534-70bd-4aba-a960-7e9e59d4d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've listed about 30 of the keywords from reviews\n",
    "\n",
    "reviews = [\n",
    "    'Fast paced', 'Medium paced', 'Slow paced', 'Meandering','Engaging', 'Exciting', 'Neutral', \n",
    "    'Boring', 'Dense', 'Clearly written', 'Succinct', 'Effective explanations', \n",
    "    'Well organized', 'Beginner', 'Intermediate', 'Advanced', 'Layman', \n",
    "    'Comprehensive', 'Focused', 'Horror', 'Romance', 'Mystery', 'Fiction', 'Drama', 'Fantasy', 'Humor', \n",
    "    'Review', 'Classic', 'Satire', 'Exploratory', 'Philisophical', 'Crime', 'Textbook', 'Suspenseful', \n",
    "    'Romantic', 'Emotional', 'Scientific', 'Tense', 'Hopeful',\n",
    "    'Dark', 'Sad', 'Strange', 'Mysterious', 'Informative', \n",
    "    'Fearful', 'Angry', 'Highly recommend', 'Recommend', \n",
    "    'Life changing', 'Quotable', 'Underrated', 'Medium', 'Long', 'Short',\n",
    "    'Trendy', 'Accurate', 'Biased', 'Adult themes', \n",
    "    'Trigger warnings', 'Offensive language', 'Olde', 'Slang', \n",
    "    'Entertainment', 'Broaden perspective', 'Inspiration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51094f2d-6cd3-41b6-a33f-83a8694e0c2e",
   "metadata": {},
   "source": [
    "## Begin creating the matrices V, W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b983e7-67e9-4f46-a2d0-12d6313dce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Romance</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Historical Fiction</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Mystery/Thriller</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Fast paced</th>\n",
       "      <th>Medium paced</th>\n",
       "      <th>Slow paced</th>\n",
       "      <th>Meandering</th>\n",
       "      <th>Engaging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Great Gatsby</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To Kill a Mockingbird</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pride and Prejudice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moby-Dick</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War and Peace</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Catcher in the Rye</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hobbit</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulysses</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Odyssey</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime and Punishment</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane Eyre</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brave New World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wuthering Heights</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Divine Comedy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Brothers Karamazov</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Karenina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madame Bovary</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Iliad</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don Quixote</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Hundred Years of Solitude</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sound and the Fury</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Invisible Man</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beloved</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs. Dalloway</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slaughterhouse-Five</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sun Also Rises</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middlemarch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Romance  Fantasy  Historical Fiction  Horror  \\\n",
       "The Great Gatsby                   0.0      0.0                 0.0     0.0   \n",
       "To Kill a Mockingbird              1.0      1.0                 1.0     0.0   \n",
       "1984                               0.0      0.0                 0.0     1.0   \n",
       "Pride and Prejudice                1.0      0.0                 0.0     0.0   \n",
       "Moby-Dick                          0.0      1.0                 1.0     1.0   \n",
       "War and Peace                      0.0      0.0                 0.0     1.0   \n",
       "The Catcher in the Rye             0.0      1.0                 1.0     0.0   \n",
       "The Hobbit                         0.0      1.0                 0.0     0.0   \n",
       "Ulysses                            1.0      0.0                 0.0     0.0   \n",
       "The Odyssey                        0.0      1.0                 0.0     1.0   \n",
       "Crime and Punishment               1.0      0.0                 1.0     1.0   \n",
       "Jane Eyre                          0.0      1.0                 0.0     0.0   \n",
       "Brave New World                    0.0      1.0                 0.0     0.0   \n",
       "Wuthering Heights                  0.0      0.0                 1.0     0.0   \n",
       "The Divine Comedy                  1.0      0.0                 0.0     0.0   \n",
       "The Brothers Karamazov             1.0      1.0                 1.0     1.0   \n",
       "Anna Karenina                      0.0      1.0                 0.0     1.0   \n",
       "Madame Bovary                      1.0      0.0                 1.0     0.0   \n",
       "The Iliad                          0.0      1.0                 0.0     0.0   \n",
       "Don Quixote                        1.0      1.0                 0.0     0.0   \n",
       "One Hundred Years of Solitude      1.0      0.0                 1.0     1.0   \n",
       "The Sound and the Fury             0.0      0.0                 0.0     1.0   \n",
       "Invisible Man                      1.0      1.0                 1.0     0.0   \n",
       "Beloved                            0.0      0.0                 0.0     1.0   \n",
       "Mrs. Dalloway                      0.0      1.0                 1.0     1.0   \n",
       "Slaughterhouse-Five                1.0      1.0                 1.0     1.0   \n",
       "The Sun Also Rises                 0.0      0.0                 0.0     1.0   \n",
       "Middlemarch                        0.0      1.0                 0.0     1.0   \n",
       "\n",
       "                               Humor  Literature  Mystery/Thriller  \\\n",
       "The Great Gatsby                 1.0         0.0               0.0   \n",
       "To Kill a Mockingbird            1.0         0.0               0.0   \n",
       "1984                             1.0         1.0               1.0   \n",
       "Pride and Prejudice              1.0         1.0               1.0   \n",
       "Moby-Dick                        0.0         1.0               0.0   \n",
       "War and Peace                    0.0         1.0               1.0   \n",
       "The Catcher in the Rye           0.0         1.0               1.0   \n",
       "The Hobbit                       0.0         0.0               0.0   \n",
       "Ulysses                          0.0         1.0               0.0   \n",
       "The Odyssey                      1.0         0.0               1.0   \n",
       "Crime and Punishment             0.0         0.0               1.0   \n",
       "Jane Eyre                        1.0         0.0               1.0   \n",
       "Brave New World                  0.0         1.0               1.0   \n",
       "Wuthering Heights                1.0         1.0               0.0   \n",
       "The Divine Comedy                0.0         1.0               1.0   \n",
       "The Brothers Karamazov           1.0         1.0               1.0   \n",
       "Anna Karenina                    1.0         1.0               1.0   \n",
       "Madame Bovary                    1.0         0.0               0.0   \n",
       "The Iliad                        0.0         0.0               0.0   \n",
       "Don Quixote                      0.0         0.0               1.0   \n",
       "One Hundred Years of Solitude    1.0         0.0               0.0   \n",
       "The Sound and the Fury           0.0         0.0               1.0   \n",
       "Invisible Man                    0.0         0.0               1.0   \n",
       "Beloved                          0.0         1.0               0.0   \n",
       "Mrs. Dalloway                    0.0         0.0               1.0   \n",
       "Slaughterhouse-Five              1.0         0.0               0.0   \n",
       "The Sun Also Rises               0.0         1.0               0.0   \n",
       "Middlemarch                      1.0         0.0               0.0   \n",
       "\n",
       "                               Science Fiction  Fast paced  Medium paced  \\\n",
       "The Great Gatsby                           0.0       0.420         0.561   \n",
       "To Kill a Mockingbird                      0.0       0.597         0.727   \n",
       "1984                                       0.0       0.071         0.496   \n",
       "Pride and Prejudice                        1.0       0.231         0.416   \n",
       "Moby-Dick                                  1.0       0.897         0.973   \n",
       "War and Peace                              1.0       0.262         0.170   \n",
       "The Catcher in the Rye                     1.0       0.038         0.164   \n",
       "The Hobbit                                 0.0       0.614         0.459   \n",
       "Ulysses                                    0.0       0.461         0.114   \n",
       "The Odyssey                                1.0       0.455         0.146   \n",
       "Crime and Punishment                       0.0       0.071         0.063   \n",
       "Jane Eyre                                  1.0       0.040         0.279   \n",
       "Brave New World                            1.0       0.055         0.053   \n",
       "Wuthering Heights                          0.0       0.285         0.675   \n",
       "The Divine Comedy                          0.0       0.345         0.595   \n",
       "The Brothers Karamazov                     0.0       0.359         0.566   \n",
       "Anna Karenina                              0.0       0.820         0.262   \n",
       "Madame Bovary                              0.0       0.570         0.632   \n",
       "The Iliad                                  1.0       0.129         0.661   \n",
       "Don Quixote                                1.0       0.594         0.780   \n",
       "One Hundred Years of Solitude              0.0       0.561         0.275   \n",
       "The Sound and the Fury                     1.0       0.106         0.927   \n",
       "Invisible Man                              1.0       0.914         0.349   \n",
       "Beloved                                    0.0       0.598         0.630   \n",
       "Mrs. Dalloway                              1.0       0.639         0.536   \n",
       "Slaughterhouse-Five                        1.0       0.699         0.133   \n",
       "The Sun Also Rises                         0.0       0.133         0.893   \n",
       "Middlemarch                                1.0       0.560         0.105   \n",
       "\n",
       "                               Slow paced  Meandering  Engaging  \n",
       "The Great Gatsby                    0.798       0.050     0.846  \n",
       "To Kill a Mockingbird               0.906       0.042     0.045  \n",
       "1984                                0.019       0.364     0.910  \n",
       "Pride and Prejudice                 0.544       0.110     0.561  \n",
       "Moby-Dick                           0.559       0.609     0.822  \n",
       "War and Peace                       0.325       0.456     0.569  \n",
       "The Catcher in the Rye              0.553       0.663     0.098  \n",
       "The Hobbit                          0.883       0.788     0.804  \n",
       "Ulysses                             0.837       0.768     0.076  \n",
       "The Odyssey                         0.543       0.306     0.493  \n",
       "Crime and Punishment                0.750       0.505     0.116  \n",
       "Jane Eyre                           0.856       0.478     0.943  \n",
       "Brave New World                     0.684       0.957     0.913  \n",
       "Wuthering Heights                   0.793       0.893     0.680  \n",
       "The Divine Comedy                   0.693       0.068     0.570  \n",
       "The Brothers Karamazov              0.100       0.529     0.093  \n",
       "Anna Karenina                       0.672       0.665     0.716  \n",
       "Madame Bovary                       0.171       0.548     0.325  \n",
       "The Iliad                           0.725       0.795     0.165  \n",
       "Don Quixote                         0.884       0.061     0.968  \n",
       "One Hundred Years of Solitude       0.703       0.104     0.285  \n",
       "The Sound and the Fury              0.211       0.039     0.064  \n",
       "Invisible Man                       0.486       0.013     0.680  \n",
       "Beloved                             0.071       0.951     0.579  \n",
       "Mrs. Dalloway                       0.442       0.566     0.191  \n",
       "Slaughterhouse-Five                 0.895       0.506     0.909  \n",
       "The Sun Also Rises                  0.849       0.213     0.666  \n",
       "Middlemarch                         0.518       0.944     0.461  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the columns of the csv will start with the genres/ subjects\n",
    "# then I've added the first five of the keywords from reviews to create all of our columns\n",
    "\n",
    "dataset = pd.DataFrame(m, columns = [\"Romance\", \"Fantasy\", \"Historical Fiction\", \"Horror\", \"Humor\", \"Literature\", \n",
    "                 \"Mystery/Thriller\", \"Science Fiction\"] + reviews[:5])\n",
    "\n",
    "# the rows of the csv file will have book titles\n",
    "dataset.index = [\n",
    "    \"The Great Gatsby\", \"To Kill a Mockingbird\", \"1984\", \"Pride and Prejudice\", \"Moby-Dick\", \"War and Peace\", \"The Catcher in the Rye\",\n",
    "    \"The Hobbit\", \"Ulysses\", \"The Odyssey\", \"Crime and Punishment\", \"Jane Eyre\", \"Brave New World\", \"Wuthering Heights\", \"The Divine Comedy\",\n",
    "    \"The Brothers Karamazov\",  \"Anna Karenina\",  \"Madame Bovary\",  \"The Iliad\",  \"Don Quixote\",  \"One Hundred Years of Solitude\",  \"The Sound and the Fury\",\n",
    "    \"Invisible Man\", \"Beloved\", \"Mrs. Dalloway\", \"Slaughterhouse-Five\", \"The Sun Also Rises\",\n",
    "    \"Middlemarch\"]\n",
    "\n",
    "\n",
    "# V is our csv file represented as a matrix to mimic: V = W X H\n",
    "V = dataset\n",
    "\n",
    "# to make it easier to see, I made our csv file into a pandas dataframe\n",
    "df = pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158b1115-dae9-49f4-98c1-af5756d87e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to estimate the possible shared \"topics\", I've created a list of 5 topics\n",
    "topics = ['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5']\n",
    "\n",
    "# here we're able to define the model using the NMF package which we'll use to decompose W and H\n",
    "model = NMF(n_components=5, init='random', random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2b45e0-2da7-4cf3-af90-e4b9278ddf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.14</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic 1  Topic 2  Topic 3  Topic 4  Topic 5\n",
       "0      1.09     0.00     0.09     0.02     0.16\n",
       "1      0.90     0.22     0.84     0.00     0.00\n",
       "2      0.75     0.00     0.00     0.57     1.03\n",
       "3      0.60     0.40     0.38     0.00     0.83\n",
       "4      0.17     0.71     0.34     0.72     0.73\n",
       "5      0.00     0.51     0.00     0.59     0.90\n",
       "6      0.00     0.84     0.28     0.03     0.75\n",
       "7      0.45     0.52     0.11     0.05     0.21\n",
       "8      0.08     0.00     0.47     0.00     0.86\n",
       "9      0.76     0.88     0.00     0.58     0.00\n",
       "10     0.00     0.19     0.68     0.57     0.28\n",
       "11     0.90     0.97     0.00     0.00     0.14\n",
       "12     0.05     0.97     0.00     0.00     0.96\n",
       "13     0.94     0.00     0.35     0.08     0.93\n",
       "14     0.01     0.14     0.47     0.00     1.07\n",
       "15     0.60     0.23     0.63     0.59     0.77\n",
       "16     0.94     0.40     0.00     0.61     0.91\n",
       "17     0.81     0.00     0.75     0.06     0.06\n",
       "18     0.14     0.87     0.05     0.04     0.01\n",
       "19     0.14     1.08     0.49     0.00     0.18\n",
       "20     0.81     0.00     0.71     0.59     0.00\n",
       "21     0.00     0.58     0.00     0.63     0.16\n",
       "22     0.00     1.00     0.79     0.02     0.02\n",
       "23     0.14     0.00     0.00     0.68     0.97\n",
       "24     0.00     0.98     0.31     0.70     0.06\n",
       "25     0.94     0.67     0.66     0.59     0.00\n",
       "26     0.21     0.00     0.02     0.60     0.96\n",
       "27     0.90     0.69     0.00     0.62     0.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating W from V by taking in the rows of V and the columns from topics\n",
    "W = model.fit_transform(V)\n",
    "\n",
    "# creating the other matrix H based on the topics and columns of V\n",
    "H = pd.DataFrame(model.components_)\n",
    "\n",
    "# Renaming the indices of H to reflect the topics\n",
    "H.index = topics\n",
    "\n",
    "# creating a new numpy array W_df to reflect the dataframe, not the model matrix\n",
    "# !!!!!!!!!! I rounded to two decimal places just so I can see the data better right now !!!!!!!!!!\n",
    "# also ensures the columns of W match the rows of H\n",
    "W_df = pd.DataFrame(np.round(W, 2), columns = H.index)\n",
    "W_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2e775c-e5b3-40a7-9cf3-d3d033de2c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Romance</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Historical Fiction</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Mystery/Thriller</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Fast paced</th>\n",
       "      <th>Medium paced</th>\n",
       "      <th>Slow paced</th>\n",
       "      <th>Meandering</th>\n",
       "      <th>Engaging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>1.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Romance  Fantasy  Historical Fiction  Horror  Humor  Literature  \\\n",
       "Topic 1     0.00     0.23                0.00    0.00   1.10        0.00   \n",
       "Topic 2     0.00     0.97                0.00    0.00   0.00        0.00   \n",
       "Topic 3     1.38     0.08                1.16    0.00   0.04        0.00   \n",
       "Topic 4     0.00     0.00                0.27    1.61   0.00        0.00   \n",
       "Topic 5     0.00     0.00                0.00    0.00   0.00        1.08   \n",
       "\n",
       "         Mystery/Thriller  Science Fiction  Fast paced  Medium paced  \\\n",
       "Topic 1              0.00             0.00        0.18          0.14   \n",
       "Topic 2              0.69             1.08        0.21          0.17   \n",
       "Topic 3              0.08             0.00        0.45          0.31   \n",
       "Topic 4              0.04             0.08        0.28          0.20   \n",
       "Topic 5              0.44             0.00        0.02          0.27   \n",
       "\n",
       "         Slow paced  Meandering  Engaging  \n",
       "Topic 1        0.34        0.19      0.40  \n",
       "Topic 2        0.43        0.31      0.40  \n",
       "Topic 3        0.39        0.00      0.00  \n",
       "Topic 4        0.00        0.17      0.00  \n",
       "Topic 5        0.23        0.37      0.36  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basically repeating everything from W but respectively for H\n",
    "H.index = topics\n",
    "H.columns = V.columns\n",
    "H_df = pd.DataFrame(np.round(H,2))\n",
    "H_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e438289c-f584-4243-bdf1-590eb8494516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Romance</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Historical Fiction</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Mystery/Thriller</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Fast paced</th>\n",
       "      <th>Medium paced</th>\n",
       "      <th>Slow paced</th>\n",
       "      <th>Meandering</th>\n",
       "      <th>Engaging</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Great Gatsby</th>\n",
       "      <td>0.06177</td>\n",
       "      <td>0.07156</td>\n",
       "      <td>0.06089</td>\n",
       "      <td>0.05654</td>\n",
       "      <td>0.18411</td>\n",
       "      <td>0.06510</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>0.05508</td>\n",
       "      <td>0.06996</td>\n",
       "      <td>0.06866</td>\n",
       "      <td>0.08507</td>\n",
       "      <td>0.07218</td>\n",
       "      <td>0.08974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To Kill a Mockingbird</th>\n",
       "      <td>0.13872</td>\n",
       "      <td>0.07093</td>\n",
       "      <td>0.11535</td>\n",
       "      <td>0.04380</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.04349</td>\n",
       "      <td>0.05403</td>\n",
       "      <td>0.05523</td>\n",
       "      <td>0.07801</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.08931</td>\n",
       "      <td>0.05548</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.04512</td>\n",
       "      <td>0.05356</td>\n",
       "      <td>0.05243</td>\n",
       "      <td>0.11237</td>\n",
       "      <td>0.10241</td>\n",
       "      <td>0.13573</td>\n",
       "      <td>0.07201</td>\n",
       "      <td>0.04692</td>\n",
       "      <td>0.06167</td>\n",
       "      <td>0.07360</td>\n",
       "      <td>0.07303</td>\n",
       "      <td>0.08357</td>\n",
       "      <td>0.08759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pride and Prejudice</th>\n",
       "      <td>0.07430</td>\n",
       "      <td>0.07704</td>\n",
       "      <td>0.06816</td>\n",
       "      <td>0.04404</td>\n",
       "      <td>0.08649</td>\n",
       "      <td>0.10701</td>\n",
       "      <td>0.08569</td>\n",
       "      <td>0.06805</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>0.07170</td>\n",
       "      <td>0.08911</td>\n",
       "      <td>0.07600</td>\n",
       "      <td>0.08828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moby-Dick</th>\n",
       "      <td>0.06175</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.06940</td>\n",
       "      <td>0.12266</td>\n",
       "      <td>0.04675</td>\n",
       "      <td>0.08441</td>\n",
       "      <td>0.09132</td>\n",
       "      <td>0.08764</td>\n",
       "      <td>0.06663</td>\n",
       "      <td>0.06947</td>\n",
       "      <td>0.07402</td>\n",
       "      <td>0.07323</td>\n",
       "      <td>0.07094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War and Peace</th>\n",
       "      <td>0.04577</td>\n",
       "      <td>0.07471</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>0.11726</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.12053</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.08265</td>\n",
       "      <td>0.06101</td>\n",
       "      <td>0.07135</td>\n",
       "      <td>0.06954</td>\n",
       "      <td>0.08234</td>\n",
       "      <td>0.07740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Catcher in the Rye</th>\n",
       "      <td>0.06480</td>\n",
       "      <td>0.10083</td>\n",
       "      <td>0.06117</td>\n",
       "      <td>0.04572</td>\n",
       "      <td>0.04421</td>\n",
       "      <td>0.09807</td>\n",
       "      <td>0.11062</td>\n",
       "      <td>0.10861</td>\n",
       "      <td>0.06044</td>\n",
       "      <td>0.06764</td>\n",
       "      <td>0.08258</td>\n",
       "      <td>0.07523</td>\n",
       "      <td>0.08008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hobbit</th>\n",
       "      <td>0.06215</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.06144</td>\n",
       "      <td>0.05787</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.06750</td>\n",
       "      <td>0.08525</td>\n",
       "      <td>0.09475</td>\n",
       "      <td>0.06912</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>0.08509</td>\n",
       "      <td>0.07501</td>\n",
       "      <td>0.08513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulysses</th>\n",
       "      <td>0.10139</td>\n",
       "      <td>0.05594</td>\n",
       "      <td>0.09116</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.05885</td>\n",
       "      <td>0.13370</td>\n",
       "      <td>0.07992</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.06742</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>0.07921</td>\n",
       "      <td>0.07396</td>\n",
       "      <td>0.07460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Odyssey</th>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.11764</td>\n",
       "      <td>0.04869</td>\n",
       "      <td>0.10529</td>\n",
       "      <td>0.09622</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.07863</td>\n",
       "      <td>0.11353</td>\n",
       "      <td>0.06760</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>0.07837</td>\n",
       "      <td>0.07001</td>\n",
       "      <td>0.08008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime and Punishment</th>\n",
       "      <td>0.12099</td>\n",
       "      <td>0.05991</td>\n",
       "      <td>0.12129</td>\n",
       "      <td>0.11803</td>\n",
       "      <td>0.04854</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.06585</td>\n",
       "      <td>0.06067</td>\n",
       "      <td>0.07883</td>\n",
       "      <td>0.07296</td>\n",
       "      <td>0.07100</td>\n",
       "      <td>0.06129</td>\n",
       "      <td>0.05650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane Eyre</th>\n",
       "      <td>0.04207</td>\n",
       "      <td>0.13313</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.11299</td>\n",
       "      <td>0.04882</td>\n",
       "      <td>0.08722</td>\n",
       "      <td>0.12024</td>\n",
       "      <td>0.06056</td>\n",
       "      <td>0.05831</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.09280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brave New World</th>\n",
       "      <td>0.04172</td>\n",
       "      <td>0.10792</td>\n",
       "      <td>0.04158</td>\n",
       "      <td>0.04158</td>\n",
       "      <td>0.04390</td>\n",
       "      <td>0.11657</td>\n",
       "      <td>0.12324</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.05231</td>\n",
       "      <td>0.06378</td>\n",
       "      <td>0.07942</td>\n",
       "      <td>0.08086</td>\n",
       "      <td>0.08823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wuthering Heights</th>\n",
       "      <td>0.07247</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.06829</td>\n",
       "      <td>0.05057</td>\n",
       "      <td>0.12675</td>\n",
       "      <td>0.12117</td>\n",
       "      <td>0.06878</td>\n",
       "      <td>0.04473</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.07349</td>\n",
       "      <td>0.08625</td>\n",
       "      <td>0.07623</td>\n",
       "      <td>0.09026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Divine Comedy</th>\n",
       "      <td>0.09358</td>\n",
       "      <td>0.05756</td>\n",
       "      <td>0.08391</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.04993</td>\n",
       "      <td>0.15316</td>\n",
       "      <td>0.08807</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>0.06304</td>\n",
       "      <td>0.07639</td>\n",
       "      <td>0.07893</td>\n",
       "      <td>0.07521</td>\n",
       "      <td>0.07565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Brothers Karamazov</th>\n",
       "      <td>0.09327</td>\n",
       "      <td>0.05856</td>\n",
       "      <td>0.09490</td>\n",
       "      <td>0.10064</td>\n",
       "      <td>0.07730</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.06844</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.07232</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06878</td>\n",
       "      <td>0.07131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Karenina</th>\n",
       "      <td>0.03926</td>\n",
       "      <td>0.07210</td>\n",
       "      <td>0.04612</td>\n",
       "      <td>0.10403</td>\n",
       "      <td>0.11007</td>\n",
       "      <td>0.10371</td>\n",
       "      <td>0.07863</td>\n",
       "      <td>0.06337</td>\n",
       "      <td>0.06092</td>\n",
       "      <td>0.06878</td>\n",
       "      <td>0.07826</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>0.09242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madame Bovary</th>\n",
       "      <td>0.13609</td>\n",
       "      <td>0.06147</td>\n",
       "      <td>0.11708</td>\n",
       "      <td>0.05296</td>\n",
       "      <td>0.12095</td>\n",
       "      <td>0.05109</td>\n",
       "      <td>0.05231</td>\n",
       "      <td>0.04822</td>\n",
       "      <td>0.07925</td>\n",
       "      <td>0.06969</td>\n",
       "      <td>0.08538</td>\n",
       "      <td>0.05795</td>\n",
       "      <td>0.06758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Iliad</th>\n",
       "      <td>0.05587</td>\n",
       "      <td>0.12599</td>\n",
       "      <td>0.05593</td>\n",
       "      <td>0.05606</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.05322</td>\n",
       "      <td>0.09635</td>\n",
       "      <td>0.13431</td>\n",
       "      <td>0.06648</td>\n",
       "      <td>0.06364</td>\n",
       "      <td>0.08103</td>\n",
       "      <td>0.07133</td>\n",
       "      <td>0.07859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don Quixote</th>\n",
       "      <td>0.08140</td>\n",
       "      <td>0.12613</td>\n",
       "      <td>0.07296</td>\n",
       "      <td>0.04121</td>\n",
       "      <td>0.04894</td>\n",
       "      <td>0.05017</td>\n",
       "      <td>0.09764</td>\n",
       "      <td>0.13273</td>\n",
       "      <td>0.06616</td>\n",
       "      <td>0.06176</td>\n",
       "      <td>0.08605</td>\n",
       "      <td>0.06334</td>\n",
       "      <td>0.07149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Hundred Years of Solitude</th>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.05627</td>\n",
       "      <td>0.11778</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.11092</td>\n",
       "      <td>0.04408</td>\n",
       "      <td>0.04772</td>\n",
       "      <td>0.04608</td>\n",
       "      <td>0.08283</td>\n",
       "      <td>0.06925</td>\n",
       "      <td>0.07608</td>\n",
       "      <td>0.05695</td>\n",
       "      <td>0.06078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sound and the Fury</th>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.09157</td>\n",
       "      <td>0.06162</td>\n",
       "      <td>0.14349</td>\n",
       "      <td>0.05195</td>\n",
       "      <td>0.06138</td>\n",
       "      <td>0.08536</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.07042</td>\n",
       "      <td>0.06807</td>\n",
       "      <td>0.06897</td>\n",
       "      <td>0.07336</td>\n",
       "      <td>0.06933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Invisible Man</th>\n",
       "      <td>0.12076</td>\n",
       "      <td>0.11356</td>\n",
       "      <td>0.10188</td>\n",
       "      <td>0.04169</td>\n",
       "      <td>0.04163</td>\n",
       "      <td>0.04102</td>\n",
       "      <td>0.08636</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.07135</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>0.08413</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>0.06050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beloved</th>\n",
       "      <td>0.04989</td>\n",
       "      <td>0.05141</td>\n",
       "      <td>0.05973</td>\n",
       "      <td>0.14826</td>\n",
       "      <td>0.05820</td>\n",
       "      <td>0.14153</td>\n",
       "      <td>0.07813</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.06309</td>\n",
       "      <td>0.07547</td>\n",
       "      <td>0.06510</td>\n",
       "      <td>0.08209</td>\n",
       "      <td>0.07477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs. Dalloway</th>\n",
       "      <td>0.06283</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.07087</td>\n",
       "      <td>0.12622</td>\n",
       "      <td>0.04163</td>\n",
       "      <td>0.04404</td>\n",
       "      <td>0.08787</td>\n",
       "      <td>0.12580</td>\n",
       "      <td>0.07068</td>\n",
       "      <td>0.06274</td>\n",
       "      <td>0.07131</td>\n",
       "      <td>0.06428</td>\n",
       "      <td>0.06227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slaughterhouse-Five</th>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.09060</td>\n",
       "      <td>0.09165</td>\n",
       "      <td>0.09265</td>\n",
       "      <td>0.10455</td>\n",
       "      <td>0.03612</td>\n",
       "      <td>0.06177</td>\n",
       "      <td>0.07780</td>\n",
       "      <td>0.07816</td>\n",
       "      <td>0.06384</td>\n",
       "      <td>0.08502</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.06838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sun Also Rises</th>\n",
       "      <td>0.05192</td>\n",
       "      <td>0.05284</td>\n",
       "      <td>0.06057</td>\n",
       "      <td>0.13203</td>\n",
       "      <td>0.06346</td>\n",
       "      <td>0.14113</td>\n",
       "      <td>0.07836</td>\n",
       "      <td>0.05252</td>\n",
       "      <td>0.06369</td>\n",
       "      <td>0.07599</td>\n",
       "      <td>0.06766</td>\n",
       "      <td>0.08255</td>\n",
       "      <td>0.07726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middlemarch</th>\n",
       "      <td>0.04295</td>\n",
       "      <td>0.10377</td>\n",
       "      <td>0.05077</td>\n",
       "      <td>0.11625</td>\n",
       "      <td>0.11644</td>\n",
       "      <td>0.04295</td>\n",
       "      <td>0.07094</td>\n",
       "      <td>0.09499</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>0.06216</td>\n",
       "      <td>0.07806</td>\n",
       "      <td>0.07035</td>\n",
       "      <td>0.08088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Romance  Fantasy  Historical Fiction   Horror  \\\n",
       "Title                                                                          \n",
       "The Great Gatsby               0.06177  0.07156             0.06089  0.05654   \n",
       "To Kill a Mockingbird          0.13872  0.07093             0.11535  0.04380   \n",
       "1984                           0.04512  0.05356             0.05243  0.11237   \n",
       "Pride and Prejudice            0.07430  0.07704             0.06816  0.04404   \n",
       "Moby-Dick                      0.06175  0.08178             0.06940  0.12266   \n",
       "War and Peace                  0.04577  0.07471             0.05346  0.11726   \n",
       "The Catcher in the Rye         0.06480  0.10083             0.06117  0.04572   \n",
       "The Hobbit                     0.06215  0.09968             0.06144  0.05787   \n",
       "Ulysses                        0.10139  0.05594             0.09116  0.05302   \n",
       "The Odyssey                    0.04167  0.11764             0.04869  0.10529   \n",
       "Crime and Punishment           0.12099  0.05991             0.12129  0.11803   \n",
       "Jane Eyre                      0.04207  0.13313             0.04205  0.04205   \n",
       "Brave New World                0.04172  0.10792             0.04158  0.04158   \n",
       "Wuthering Heights              0.07247  0.05689             0.06829  0.05057   \n",
       "The Divine Comedy              0.09358  0.05756             0.08391  0.04833   \n",
       "The Brothers Karamazov         0.09327  0.05856             0.09490  0.10064   \n",
       "Anna Karenina                  0.03926  0.07210             0.04612  0.10403   \n",
       "Madame Bovary                  0.13609  0.06147             0.11708  0.05296   \n",
       "The Iliad                      0.05587  0.12599             0.05593  0.05606   \n",
       "Don Quixote                    0.08140  0.12613             0.07296  0.04121   \n",
       "One Hundred Years of Solitude  0.11750  0.05627             0.11778  0.11375   \n",
       "The Sound and the Fury         0.05198  0.09157             0.06162  0.14349   \n",
       "Invisible Man                  0.12076  0.11356             0.10188  0.04169   \n",
       "Beloved                        0.04989  0.05141             0.05973  0.14826   \n",
       "Mrs. Dalloway                  0.06283  0.10945             0.07087  0.12622   \n",
       "Slaughterhouse-Five            0.09065  0.09060             0.09165  0.09265   \n",
       "The Sun Also Rises             0.05192  0.05284             0.06057  0.13203   \n",
       "Middlemarch                    0.04295  0.10377             0.05077  0.11625   \n",
       "\n",
       "                                 Humor  Literature  Mystery/Thriller  \\\n",
       "Title                                                                  \n",
       "The Great Gatsby               0.18411     0.06510           0.05933   \n",
       "To Kill a Mockingbird          0.12146     0.04349           0.05403   \n",
       "1984                           0.10241     0.13573           0.07201   \n",
       "Pride and Prejudice            0.08649     0.10701           0.08569   \n",
       "Moby-Dick                      0.04675     0.08441           0.09132   \n",
       "War and Peace                  0.04562     0.12053           0.09836   \n",
       "The Catcher in the Rye         0.04421     0.09807           0.11062   \n",
       "The Hobbit                     0.08811     0.06750           0.08525   \n",
       "Ulysses                        0.05885     0.13370           0.07992   \n",
       "The Odyssey                    0.09622     0.04167           0.07863   \n",
       "Crime and Punishment           0.04854     0.06413           0.06585   \n",
       "Jane Eyre                      0.11299     0.04882           0.08722   \n",
       "Brave New World                0.04390     0.11657           0.12324   \n",
       "Wuthering Heights              0.12675     0.12117           0.06878   \n",
       "The Divine Comedy              0.04993     0.15316           0.08807   \n",
       "The Brothers Karamazov         0.07730     0.08900           0.06844   \n",
       "Anna Karenina                  0.11007     0.10371           0.07863   \n",
       "Madame Bovary                  0.12095     0.05109           0.05231   \n",
       "The Iliad                      0.06120     0.05322           0.09635   \n",
       "Don Quixote                    0.04894     0.05017           0.09764   \n",
       "One Hundred Years of Solitude  0.11092     0.04408           0.04772   \n",
       "The Sound and the Fury         0.05195     0.06138           0.08536   \n",
       "Invisible Man                  0.04163     0.04102           0.08636   \n",
       "Beloved                        0.05820     0.14153           0.07813   \n",
       "Mrs. Dalloway                  0.04163     0.04404           0.08787   \n",
       "Slaughterhouse-Five            0.10455     0.03612           0.06177   \n",
       "The Sun Also Rises             0.06346     0.14113           0.07836   \n",
       "Middlemarch                    0.11644     0.04295           0.07094   \n",
       "\n",
       "                               Science Fiction  Fast paced  Medium paced  \\\n",
       "Title                                                                      \n",
       "The Great Gatsby                       0.05508     0.06996       0.06866   \n",
       "To Kill a Mockingbird                  0.05523     0.07801       0.06635   \n",
       "1984                                   0.04692     0.06167       0.07360   \n",
       "Pride and Prejudice                    0.06805     0.06412       0.07170   \n",
       "Moby-Dick                              0.08764     0.06663       0.06947   \n",
       "War and Peace                          0.08265     0.06101       0.07135   \n",
       "The Catcher in the Rye                 0.10861     0.06044       0.06764   \n",
       "The Hobbit                             0.09475     0.06912       0.06890   \n",
       "Ulysses                                0.05302     0.06742       0.07782   \n",
       "The Odyssey                            0.11353     0.06760       0.06059   \n",
       "Crime and Punishment                   0.06067     0.07883       0.07296   \n",
       "Jane Eyre                              0.12024     0.06056       0.05831   \n",
       "Brave New World                        0.11890     0.05231       0.06378   \n",
       "Wuthering Heights                      0.04473     0.06413       0.07349   \n",
       "The Divine Comedy                      0.05623     0.06304       0.07639   \n",
       "The Brothers Karamazov                 0.05198     0.07232       0.07389   \n",
       "Anna Karenina                          0.06337     0.06092       0.06878   \n",
       "Madame Bovary                          0.04822     0.07925       0.06969   \n",
       "The Iliad                              0.13431     0.06648       0.06364   \n",
       "Don Quixote                            0.13273     0.06616       0.06176   \n",
       "One Hundred Years of Solitude          0.04608     0.08283       0.06925   \n",
       "The Sound and the Fury                 0.10250     0.07042       0.06807   \n",
       "Invisible Man                          0.11980     0.07135       0.06171   \n",
       "Beloved                                0.05233     0.06309       0.07547   \n",
       "Mrs. Dalloway                          0.12580     0.07068       0.06274   \n",
       "Slaughterhouse-Five                    0.07780     0.07816       0.06384   \n",
       "The Sun Also Rises                     0.05252     0.06369       0.07599   \n",
       "Middlemarch                            0.09499     0.06950       0.06216   \n",
       "\n",
       "                               Slow paced  Meandering  Engaging  \n",
       "Title                                                            \n",
       "The Great Gatsby                  0.08507     0.07218   0.08974  \n",
       "To Kill a Mockingbird             0.08931     0.05548   0.06784  \n",
       "1984                              0.07303     0.08357   0.08759  \n",
       "Pride and Prejudice               0.08911     0.07600   0.08828  \n",
       "Moby-Dick                         0.07402     0.07323   0.07094  \n",
       "War and Peace                     0.06954     0.08234   0.07740  \n",
       "The Catcher in the Rye            0.08258     0.07523   0.08008  \n",
       "The Hobbit                        0.08509     0.07501   0.08513  \n",
       "Ulysses                           0.07921     0.07396   0.07460  \n",
       "The Odyssey                       0.07837     0.07001   0.08008  \n",
       "Crime and Punishment              0.07100     0.06129   0.05650  \n",
       "Jane Eyre                         0.08862     0.07115   0.09280  \n",
       "Brave New World                   0.07942     0.08086   0.08823  \n",
       "Wuthering Heights                 0.08625     0.07623   0.09026  \n",
       "The Divine Comedy                 0.07893     0.07521   0.07565  \n",
       "The Brothers Karamazov            0.07963     0.06878   0.07131  \n",
       "Anna Karenina                     0.07826     0.08233   0.09242  \n",
       "Madame Bovary                     0.08538     0.05795   0.06758  \n",
       "The Iliad                         0.08103     0.07133   0.07859  \n",
       "Don Quixote                       0.08605     0.06334   0.07149  \n",
       "One Hundred Years of Solitude     0.07608     0.05695   0.06078  \n",
       "The Sound and the Fury            0.06897     0.07336   0.06933  \n",
       "Invisible Man                     0.08413     0.05560   0.06050  \n",
       "Beloved                           0.06510     0.08209   0.07477  \n",
       "Mrs. Dalloway                     0.07131     0.06428   0.06227  \n",
       "Slaughterhouse-Five               0.08502     0.05883   0.06838  \n",
       "The Sun Also Rises                0.06766     0.08255   0.07726  \n",
       "Middlemarch                       0.07806     0.07035   0.08088  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing softmax so that every number is converted to a probability\n",
    "softmax = keras.layers.Softmax()\n",
    "\n",
    "# actually applying NMF again through matrix-multiplication to reconstruct the approximation of V\n",
    "reconstructed = softmax(W @ H)\n",
    "\n",
    "# rounding decimals again to 5 for easier reading\n",
    "reconstructed = pd.DataFrame(np.round(reconstructed,5), columns=V.columns)\n",
    "reconstructed.index = V.index\n",
    "reconstructed.index.name = \"Title\"\n",
    "reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb396b5d-36f2-4307-b81c-c1981a610dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the input from the user will be a booke title, we need it to be able to be read as a number for the model\n",
    "le = LabelEncoder()\n",
    "# reconstructed[\"Title\"] = le.fit_transform(reconstructed.index)\n",
    "# reconstructed[\"Title\"] = reconstructed[\"Title\"].astype('float32')\n",
    "recon_dict = {name: reconstructed[name].values for name in reconstructed.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da10a18e-83e1-469f-a06a-1aeed7fef0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romance: dtype=float32\n",
      "Fantasy: dtype=float32\n",
      "Historical Fiction: dtype=float32\n",
      "Horror: dtype=float32\n",
      "Humor: dtype=float32\n",
      "Literature: dtype=float32\n",
      "Mystery/Thriller: dtype=float32\n",
      "Science Fiction: dtype=float32\n",
      "Fast paced: dtype=float32\n",
      "Medium paced: dtype=float32\n",
      "Slow paced: dtype=float32\n",
      "Meandering: dtype=float32\n",
      "Engaging: dtype=float32\n"
     ]
    }
   ],
   "source": [
    "# re-initializing the pandas dataframe as a tensor dataset\n",
    "data = tf.data.Dataset.from_tensor_slices(recon_dict)\n",
    "\n",
    "# just checking that \"Title\" is being read as a float:\n",
    "for key, value in recon_dict.items():\n",
    "    print(f\"{key}: dtype={value.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291c64b5-6474-4d54-8aca-3f9251ea7ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle data to reduce bias\n",
    "data = data.shuffle(buffer_size = len(data), reshuffle_each_iteration=False)\n",
    "\n",
    "# initialize the proportion of the data that we want to use for training and validating\n",
    "train_size = int(0.7*len(data))\n",
    "val_size   = int(0.1*len(data))\n",
    "\n",
    "train = data.take(train_size).batch(5)\n",
    "val   = data.skip(train_size).take(val_size).batch(5)\n",
    "test  = data.skip(train_size + val_size).batch(5)\n",
    "\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747416a-24d2-482d-9e32-8d984d0d7e38",
   "metadata": {},
   "source": [
    "## Standardizing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b02c7bd-d97b-40fa-98e9-dc82ae1df2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the inputs of titles may be inputted differently, want to standardize it, but I don't think I called this anywhere...\n",
    "def standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_punctuation = tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation),'')\n",
    "    return no_punctuation\n",
    "\n",
    "\n",
    "\n",
    "# again want to describe the input but earlier I ensured that \"Title\" was a float but now I'm pretty sure the model's\n",
    "# expecting a string \n",
    "book_input = keras.Input(\n",
    "    shape = (1,),\n",
    "    name = \"Title\",\n",
    "    dtype = \"string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a149cf7-51ac-4c35-99e2-c78857f1564b",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7769322f-32f7-44b4-835d-463cf197b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dense layers: not sure if \n",
    "main = layers.Dense(64, activation='relu')(book_input)\n",
    "main = layers.Dropout(0.2)(main)\n",
    "main = layers.Dense(32, activation='relu')(main)\n",
    "output = layers.Dense(5, name = \"Title_Output\")(main) \n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = book_input,\n",
    "    outputs = output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c91b607-b83c-4953-ac18-58f872727b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " Title (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \n",
       "\n",
       " Title_Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " Title (\u001b[38;5;33mInputLayer\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                               \u001b[38;5;34m128\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             \u001b[38;5;34m2,080\u001b[0m \n",
       "\n",
       " Title_Output (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                                \u001b[38;5;34m165\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,373</span> (9.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,373\u001b[0m (9.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,373</span> (9.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,373\u001b[0m (9.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2e4b44-9a83-49e5-a976-d52f9bf73fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model using SGD because this or Least Squares would be the best optimizers I think..\n",
    "model.compile(optimizer = \"SGD\",\n",
    "              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# prevent overfitting\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bcfa58e-86f0-4697-a7a0-7c48e12514b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing data for input \"Title\". You passed a data dictionary with keys ['Romance', 'Fantasy', 'Historical Fiction', 'Horror', 'Humor', 'Literature', 'Mystery/Thriller', 'Science Fiction', 'Fast paced', 'Medium paced', 'Slow paced', 'Meandering', 'Engaging']. Expected the following keys: ['Title']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# okay I think I figured it out the reason for the error:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# book_input is expecting the intput to be of a tensor type, but history here is exoecting I think a string \"Title\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:149\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    150\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing data for input \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    151\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a data dictionary with keys \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the following keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m     list_inputs\u001b[38;5;241m.\u001b[39mappend(inputs[name])\n\u001b[0;32m    156\u001b[0m inputs \u001b[38;5;241m=\u001b[39m list_inputs\n",
      "\u001b[1;31mValueError\u001b[0m: Missing data for input \"Title\". You passed a data dictionary with keys ['Romance', 'Fantasy', 'Historical Fiction', 'Horror', 'Humor', 'Literature', 'Mystery/Thriller', 'Science Fiction', 'Fast paced', 'Medium paced', 'Slow paced', 'Meandering', 'Engaging']. Expected the following keys: ['Title']"
     ]
    }
   ],
   "source": [
    "\n",
    "# okay I think I figured it out the reason for the error:\n",
    "# book_input is expecting the intput to be of a tensor type, but history here is exoecting I think a string \"Title\"\n",
    "\n",
    "history = model.fit(train,\n",
    "                    validation_data=val,\n",
    "                    epochs = 5,\n",
    "                    callbacks=[callback],\n",
    "                    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c074cd-ef1c-4531-a48f-669aa35b29d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2fee9-a663-4238-86be-94ad8e11d1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0d33b-da65-400a-9d78-5044522641b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PIC16B-25W)",
   "language": "python",
   "name": "pic16b-25w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
