{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d3b957-8652-4622-af76-7bd0b7e32b3b",
   "metadata": {},
   "source": [
    "## UCSD METHOD CONTINUED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d47d-4273-455d-a5ce-db58bdbb8e48",
   "metadata": {},
   "source": [
    "**Now, we are going to extract the reviews.** We currently have a draft of our final dataset, which has the one hot encoded columns of genres for each of the books that we need. This is stored in final_books_dataset.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b448d6-1358-4d3d-b358-f067592c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sentiment_worker import process_book_sentiment # I put this function in a separate .py file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ce62f3-2ec6-414c-b070-9d81a4ee9f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"user_id\": \"8842281e1d1347389f2ab93d60773d4d\", \"book_id\": \"24375664\", \"review_id\": \"5cd416f3efc3f944fce4ce2db2290d5e\", \"rating\": 5, \"review_text\": \"Mind blowingly cool. Best science fiction I've read in some time. I just loved all the descriptions of the society of the future - how they lived in trees, the notion of owning property or even getting married was gone. How every surface was a screen. \\n The undulations of how society responds to the Trisolaran threat seem surprising to me. Maybe its more the Chinese perspective, but I wouldn't have thought the ETO would exist in book 1, and I wouldn't have thought people would get so over-confident in our primitive fleet's chances given you have to think that with superior science they would have weapons - and defenses - that would just be as rifles to arrows once were. \\n But the moment when Luo Ji won as a wallfacer was just too cool. I may have actually done a fist pump. Though by the way, if the Dark Forest theory is right - and I see no reason why it wouldn't be - we as a society should probably stop broadcasting so much signal out into the universe.\", \"date_added\": \"Fri Aug 25 13:55:02 -0700 2017\", \"date_updated\": \"Mon Oct 09 08:55:59 -0700 2017\", \"read_at\": \"Sat Oct 07 00:00:00 -0700 2017\", \"started_at\": \"Sat Aug 26 00:00:00 -0700 2017\", \"n_votes\": 16, \"n_comments\": 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# file path to the reviews JSON\n",
    "file_path_to_reviews = \"goodreads_reviews_dedup.json.gz\"\n",
    "\n",
    "# try opening the file\n",
    "try: \n",
    "    with gzip.open(file_path_to_reviews, 'rt') as f:\n",
    "        first_line = f.readline()\n",
    "        print(first_line)\n",
    "except EOFError:\n",
    "    print(\"this file is corrupted or incomplete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8084b192-ca78-420d-a824-5760d87d133c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk {i}...\n",
      "                            user_id   book_id  \\\n",
      "0  8842281e1d1347389f2ab93d60773d4d  24375664   \n",
      "1  8842281e1d1347389f2ab93d60773d4d  18245960   \n",
      "2  8842281e1d1347389f2ab93d60773d4d   6392944   \n",
      "3  8842281e1d1347389f2ab93d60773d4d  22078596   \n",
      "4  8842281e1d1347389f2ab93d60773d4d   6644782   \n",
      "\n",
      "                          review_id  rating  \\\n",
      "0  5cd416f3efc3f944fce4ce2db2290d5e       5   \n",
      "1  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n",
      "2  5e212a62bced17b4dbe41150e5bb9037       3   \n",
      "3  fdd13cad0695656be99828cd75d6eb73       4   \n",
      "4  bd0df91c9d918c0e433b9ab3a9a5c451       4   \n",
      "\n",
      "                                         review_text  \\\n",
      "0  Mind blowingly cool. Best science fiction I've...   \n",
      "1  This is a special book. It started slow for ab...   \n",
      "2  I haven't read a fun mystery book in a while a...   \n",
      "3  Fun, fast paced, and disturbing tale of murder...   \n",
      "4  A fun book that gives you a sense of living in...   \n",
      "\n",
      "                       date_added                    date_updated  \\\n",
      "0  Fri Aug 25 13:55:02 -0700 2017  Mon Oct 09 08:55:59 -0700 2017   \n",
      "1  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n",
      "2  Mon Jul 24 02:48:17 -0700 2017  Sun Jul 30 09:28:03 -0700 2017   \n",
      "3  Mon Jul 24 02:33:09 -0700 2017  Sun Jul 30 10:23:54 -0700 2017   \n",
      "4  Mon Jul 24 02:28:14 -0700 2017  Thu Aug 24 00:07:20 -0700 2017   \n",
      "\n",
      "                          read_at                      started_at  n_votes  \\\n",
      "0  Sat Oct 07 00:00:00 -0700 2017  Sat Aug 26 00:00:00 -0700 2017       16   \n",
      "1  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n",
      "2  Tue Jul 25 00:00:00 -0700 2017  Mon Jul 24 00:00:00 -0700 2017        6   \n",
      "3  Sun Jul 30 15:42:05 -0700 2017  Tue Jul 25 00:00:00 -0700 2017       22   \n",
      "4  Sat Aug 05 00:00:00 -0700 2017  Sun Jul 30 00:00:00 -0700 2017        8   \n",
      "\n",
      "   n_comments  \n",
      "0           0  \n",
      "1           1  \n",
      "2           0  \n",
      "3           4  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "# this file is huge. we need to process it in chunks to prevent crashes \n",
    "# my computer crashed the first time I tried to read the json file\n",
    "\n",
    "chunk_size =10000\n",
    "\n",
    "with gzip.open(file_path_to_reviews, 'rt') as f:\n",
    "    reader = pd.read_json(f, lines=True, chunksize = chunk_size)\n",
    "\n",
    "    for i, chunk in enumerate(reader):\n",
    "        print(\"Processing chunk {i}...\")\n",
    "        print(chunk.head()) # show the first few rows of each chunk\n",
    "        break # stop after the first chunk to rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec8141-ca97-47b2-940e-6eed1a647990",
   "metadata": {},
   "source": [
    "## Define Sentiment Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d218bbb-f7b4-4e7f-b90b-16f35c1c2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved this to sentiment_worker.py\n",
    "sentiment_words = {\n",
    "    # pacing of the book\n",
    "    \"fast-paced\" : [\"intense\", \"page turner\", \"fast\", \"fast paced\", \"quick\", \"thrilling\", \"gripping\"],\n",
    "    \"slow-paced\" : [\"slow\", \"slow paced\",  \"slow pacing\", \"gradual\", \"steady\", \"builds slowly\", \"patient\"],\n",
    "    \"suspenseful\" : [\"suspense\", \"suspenseful\", \"nail biting\", \"edge of your seat\", \"tension\", \"unpredictable\"],\n",
    "    \"relaxing\" : [\"relaxing\", \"relaxed\", \"comforting\", \"cozy\", \"lighthearted\", \"gentle\", \"easygoing\"],\n",
    "\n",
    "    # themes and mood\n",
    "\n",
    "    \"romance\" : [\"romantic\", \"romance\", \"love\", \"emotional\", \"sweet\", \"dreamy\", \"steamy\", \"passionate\", \"chemistry\"],\n",
    "    \"mysterious\" : [\"mysterious\", \"mystery\", \"intriguing\", \"unraveling\", \"puzzling\", \"confusing\", \"detective\"],\n",
    "    \"philosophical\" : [\"philosophical\", \"deep\", \"existentialism\", \"helpful\"],\n",
    "    \"magical\" : [\"magical\", \"magic\", \"enchanting\", \"charming\", \"whimsical\", \"fairytale\", \"wonderous\", \"fantastical\", ],\n",
    "    \"realistic\" : [\"believable\", \"gritty\", \"grounded\", \"realistic\", \"authentic\", \"genuine\", \"slice of life\", ],\n",
    "    \"nostalgic\" : [\"nostalgic\", \"reminiscent\", \"bittersweet\", \"memories\", \"childhood\", \"wistful\", \"sentimental\"],\n",
    "    \"dark\" : [\"dark\", \"gloomy\", \"disturbing\", \"ominous\", \"gritty\", \"chiling\", \"sinister\", ],\n",
    "    \"angry\" : [\"angry\", \"rage\", \"fiery\", \"furious\", \"frustrating\", \"heated\", \"aggressive\"],\n",
    "    \"sad\" : [\"sad\", \"depression\", \"emotional\", \"tear-jerker\", \"cried\"],\n",
    "    \"funny\" : [\"funny\", \"witty\", \"hilarious\", \"laughing\", \"sarcastic\", \"light-hearted\", \"humorous\", \"entertaining\"],\n",
    "\n",
    "    # emotional impact\n",
    "    \"heartwarming\" : [\"heartwarming\", \"sweet\", \"uplifting\", \"touching\", \"moving\", \"feel-good\", \"comforting\", \"joyful\"],\n",
    "    \"heartbreaking\" : [\"painful\", \"heartbreaking\", \"tearjerking\", \"sad\", \"aching\", \"bittersweet\", \"poignant\"],\n",
    "    \"depressing\" : [\"depressing\", \"sad\", \"dark\", \"depression\", \"somber\", \"tragic\", \"dystopian\", \"crushing\", \"heavy\"],\n",
    "    \"hopeful\" : [\"hope\", \"hopeful\", \"optimistic\", \"encourage\", \"encouraging\", \"faith\", \"bright\", \"positive\"],\n",
    "    \"inspiring\" : [\"inspiring\", \"powerful\", \"thought-provoking\", \"transformative\", \"stirring\", \"soulful\", \"meaningful\"],\n",
    "    \"moving\" : [\"inspiring\",\"moving\", \"powerful\", \"resonant\",  \"profound\", \"touching\", \"resonant\", \"stirring\"],\n",
    "\n",
    "    # story depth and characters\n",
    "    \"character-driven\" : [\"character development\", \"emotional depth\", \"well written\", \"relatable\", \"personal\", \"introspective\"],\n",
    "    \"plot-driven\" : [\"action-packed\", \"plot driven\", \"adventure\", \"packed with surprises\", \"suspenseful\"],\n",
    "\n",
    "    # writing style and readability\n",
    "    \"descriptive\" : [\"descriptive\", \"vivid\", \"detailed\", \"atmospheric\", \"scenic\", \"evocative\"],\n",
    "    \"clearly-written\" : [\"clear\", \"clearly written\", \"straightforward\", \"concise\", \"easy to read\", \"smooth\"],\n",
    "    \"dense\" : [\"complex\", \"wordy\", \"intricate\", \"highly detailed\", \"wordy\", \"heavy\"],\n",
    "    \"poetic\" : [\"lyrical\", \"poetry\", \"elegant\", \"artistic\", \"expressive\", \"soulful\"],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4d2c5f-de6a-4528-af9f-ce6b46712ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 book IDs from final_books_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# load in the final_books_dataset to get the relevant book IDs\n",
    "df_books = pd.read_csv(\"final_books_dataset.csv\", dtype=str, low_memory = False)  # Read as string first\n",
    "\n",
    "# Remove NaN values and convert properly\n",
    "df_books = df_books[df_books[\"book_id\"].notna()]  # Drop rows where book_id is NaN\n",
    "df_books[\"book_id\"] = df_books[\"book_id\"].astype(float).astype(int).astype(str)  # Remove decimal\n",
    "\n",
    "book_ids = set(df_books[\"book_id\"])  # Convert to set\n",
    "\n",
    "print(f\"Loaded {len(book_ids)} book IDs from final_books_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6c658a-2ba8-43af-b0b5-8684d1ab56c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create a function to extract sentiment count\n",
    "# moved this to sentiment_worker.py\n",
    "def extract_sentiment_count(text):\n",
    "    # if the text is not a string, return a dictionary with all the sentiment categories set to 0.0\n",
    "    if not isinstance(text, str):\n",
    "        return {sentiment: 0.0 for sentiment in sentiment_words}\n",
    "\n",
    "    # extract words from text using regex, ignores punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    total_words = len(words) #count the total number of words in the review\n",
    "\n",
    "    # loops over each sentiment and its list of keywords\n",
    "    # count how many words from each sentiment category appears in the review\n",
    "    sentiment_counts = {sentiment: sum(1 for word in words if word in keywords) \n",
    "                        for sentiment, keywords in sentiment_words.items()}\n",
    "\n",
    "    return sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad1fea4-47ab-4d7a-957e-14e8de6d3d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fast-paced': 1, 'slow-paced': 0, 'suspenseful': 0, 'relaxing': 0, 'romance': 0, 'mysterious': 0, 'philosophical': 0, 'magical': 0, 'realistic': 0, 'nostalgic': 0, 'dark': 0, 'angry': 0, 'sad': 0, 'funny': 0, 'heartwarming': 1, 'heartbreaking': 0, 'depressing': 0, 'hopeful': 0, 'inspiring': 0, 'moving': 0, 'character-driven': 0, 'plot-driven': 0, 'descriptive': 0, 'clearly-written': 0, 'dense': 0, 'poetic': 0}\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This book was fast, exciting and heartwarming!\"\n",
    "print(extract_sentiment_count(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b76762-a298-44c0-858e-fcc3b8c7a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Reviews: 100%|██████████| 15739967/15739967 [03:34<00:00, 73298.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# we need to process the reviews in chunks and store the scores per book\n",
    "\n",
    "book_sentiment = {}\n",
    "total_lines = sum(1 for _ in gzip.open(\"goodreads_reviews_dedup.json.gz\", \"rt\", encoding=\"utf-8\"))  # Get total lines for tqdm\n",
    "\n",
    "# open the compressed file\n",
    "with gzip.open(\"goodreads_reviews_dedup.json.gz\", \"rt\", encoding=\"utf-8\") as f, tqdm(total=total_lines, desc=\"Processing Reviews\") as pbar:\n",
    "    for line in f:\n",
    "        review = json.loads(line)  # Load each review\n",
    "        book_id = str(review.get(\"book_id\", \"\"))  # make sure that book_id is a string\n",
    "        text = review.get(\"review_text\", \"\")\n",
    "\n",
    "        if book_id in book_ids:  # process books in final_books_dataset.csv\n",
    "            if book_id not in book_sentiment:\n",
    "                book_sentiment[book_id] = []\n",
    "            if len(book_sentiment[book_id]) < 50:\n",
    "                book_sentiment[book_id].append(text)\n",
    "\n",
    "        pbar.update(1) # update the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb40ece6-358d-4df5-bfc9-16a11c98e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books in dataset: 50000\n",
      "Sample book IDs from final_books_dataset.csv: ['5884082', '25660025', '20645624', '69510', '374388']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total books in dataset:\", len(book_ids))  # Should be greater than 0\n",
    "print(\"Sample book IDs from final_books_dataset.csv:\", list(book_ids)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37a87a0-8dc3-4666-b6e8-15125f58d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49951\n"
     ]
    }
   ],
   "source": [
    "print(len(book_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423db9b0-4fc7-403b-ba80-7c8d6fe2947d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book_sentiment_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Process a sample of 5000 books\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m book_sentiment_scores \u001b[38;5;241m=\u001b[39m compute_sentiment_parallel(book_sentiment_sample)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'book_sentiment_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# compute the sentiment scores (this takes a long time)\n",
    "# we will use multiprocessing for parallel processing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parallel processing with tqdm progress bar\n",
    "def compute_sentiment_parallel(book_sentiment):\n",
    "    book_sentiment_list = list(book_sentiment.items())  \n",
    "    num_workers = max(2, min(8, len(book_sentiment_list)))  # Use between 2 and 8 workers\n",
    "\n",
    "    results = {}\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        with tqdm(total=len(book_sentiment_list), desc=\"Processing Books\") as pbar:\n",
    "            futures = {executor.submit(process_book_sentiment, book): book for book in book_sentiment_list}\n",
    "            for future in as_completed(futures):\n",
    "                book_id, sentiment = future.result()\n",
    "                results[book_id] = sentiment\n",
    "                pbar.update(1)  # Update progress bar\n",
    "    return results\n",
    "\n",
    "# Process a sample of 5000 books\n",
    "book_sentiment_scores = compute_sentiment_parallel(book_sentiment_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901ddef-2b52-4182-8635-656798fadd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment scores to DataFrame\n",
    "df_sentiment = pd.DataFrame.from_dict(book_sentiment_scores, orient=\"index\").reset_index()\n",
    "df_sentiment.rename(columns={\"index\": \"book_id\"}, inplace=True)\n",
    "\n",
    "# merge this with the book dataset\n",
    "df_final = df_books.merge(df_sentiment, on=\"book_id\", how=\"left\")\n",
    "columns_to_drop = [\"isbn\", \"text_reviews_count\", \"series\", \"country_code\", \"language_code\", \n",
    "                   \"popular_shelves\", \"asin\", \"is_ebook\", \"average_rating\", \"kindle_asin\", \n",
    "                   \"similar_books\", \"description\", \"format\", \"link\", \"authors\", \"publisher\", \n",
    "                   \"num_pages\", \"publication_day\", \"isbn13\", \"publication_month\", \"edition_information\", \n",
    "                   \"publication_year\", \"image_url\", \"ratings_count\", \"work_id\", \"title_without_series\"]\n",
    "df_final = df_final.drop(columns=columns_to_drop, errors=\"ignore\") # we want to ignore the errors if the columns don't exist\n",
    "\n",
    "# save the final dataset\n",
    "df_final.to_csv(\"final_book_dataset_with_reviews.csv\", index=False)\n",
    "\n",
    "print(\"Sentiment analysis completed and dataset saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d28653-bfe6-4d99-8394-785c3ca7b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69167f6d-7f28-43a7-abd9-3835ba600555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming book_sentiment_scores is a dictionary {book_id: {sentiment: count, ...}}\n",
    "df = pd.DataFrame.from_dict(book_sentiment_scores, orient='index')\n",
    "\n",
    "# Sum sentiment occurrences across all books\n",
    "sentiment_totals = df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=sentiment_totals.index, y=sentiment_totals.values, palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Total Count\")\n",
    "plt.title(\"Sentiment Distribution Across Books\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d1851-fe9d-40a2-843e-91fe23f126de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIC16B",
   "language": "python",
   "name": "pic16b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
